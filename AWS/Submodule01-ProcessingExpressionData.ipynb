{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e3537d",
   "metadata": {},
   "source": [
    "# Processing Expression Data\n",
    "\n",
    "![](./images/Module1/Data_Processing.png)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter Notebook covers processing gene expression data, specifically focusing on datasets from the NCBI Gene Expression Omnibus (GEO) database.  It details how to browse, download, and process data from GEO using both the web interface and the `GEOquery` R package, using GSE5281 (microarray) and GSE153873 (RNA-Seq) as examples.  The notebook explains data uploading methods for user-provided data, including uploading to the Vertex AI instance and Cloud Storage Bucket.  Data processing steps are outlined, including normalization, sample condition extraction, and gene ID mapping, with distinct code examples for microarray and RNA-Seq data.  Finally, it describes how to store processed data in an Amazon S3 bucket and export data in CSV and RDS formats.\n",
    "\n",
    "## Learning Objectives:\n",
    "1. Explore data that is accessible from Gene Expression Omnibus (GEO) database.\n",
    "2. Use web-interface and R command line to download data from GEO.\n",
    "3. Use web interface to upload experiment data to the Cloud environment\n",
    "4. Learn data processing and gene mapping.\n",
    "5. Store data onto Amazon S3 bucket and export data in CSV or RDS format.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* **R:**  The core requirement.\n",
    "* **R Packages:**  The notebook explicitly installs or uses the following:\n",
    "    * `GEOquery` (from Bioconductor)\n",
    "    * `BiocManager` (for managing Bioconductor packages)\n",
    "    * `IRdisplay` (for displaying interactive elements, likely quizzes)\n",
    "    * `hgu133plus2.db` (annotation package, specific to the GPL570 microarray platform)\n",
    "    * `org.Hs.eg.db` (annotation package for human gene mappings)\n",
    "    * `readr` (for writing CSV files, though `write.csv` is base R and likely sufficient)\n",
    "\n",
    "## Get Started\n",
    "\n",
    "### Table of Contents\n",
    "1. [Browsing and Downloading from NCBI GEO](#dt-query)\n",
    "    - 1.1. [Downloading using Web Interface](#dt-webquery)\n",
    "    - 1.2. [Downloading using R Command Line](#dt-Rquery)\n",
    "2. [Uploading User-Provided Data](#dt-manual)\n",
    "3. [Data Processing and Gene Mapping](#dt-process)\n",
    "    - 3.1. [Example of Microarray Data](#dp-microarray)\n",
    "    - 3.2. [Example of RNA-Seq data](#dp-rnaseq)\n",
    "4. [Storing Data to Cloud Storage Bucket](#dt-cloud)\n",
    "5. [Exporting Data](#dt-export)\n",
    "\n",
    "<!-- 1. [Manually Upload Data to Cloud](#dt-manual)\n",
    "2. [Query Public Data Using R Command Lines:](#dt-query)\n",
    "3. [Process Data For Downstream Analysis](#dt-process)\n",
    "   - 3.1. [Data normalization](#dp-dtnorm)\n",
    "   - 3.2. [Samples Condition Extraction](#dp-samplextract)\n",
    "   - 3.3. [Gene IDs Conversion](#dp-convert)\n",
    "4. [Exporting the Data](#dt-export)\n",
    "5. [Storing files in a AWS S3 bucket](#dt-cloud) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae77e2e",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dt-query\"></a>\n",
    "## 1. Browsing and Downloading from NCBI GEO\n",
    "\n",
    "The Gene Expression Omnibus (GEO) is a public repository that accumulates and serves gene expression data, such as microarray, next-generation sequencing, and other forms of high-throughput functional genomic data, from thousands of studies submitted by the scientific community. \n",
    "The data come with written descriptions of experimental design, sample characteristics, and methodology for studies of high-throughput gene expression and genomics. \n",
    "\n",
    "<!-- headings -->\n",
    "<a id=\"dt-webquery\"></a>\n",
    "### 1.1. Downloading using Web Interface\n",
    "Browsing the content on the GEO website is user-friendly and relatively straightforward. First, users need to navigate to <a href=\"https://www.ncbi.nlm.nih.gov/geo/\"> https://www.ncbi.nlm.nih.gov/geo/</a>. The GEO website interface is shown in the figure below:\n",
    "\n",
    "![](./images/Module1/GEO_Website.png)\n",
    "\n",
    "The most straight-forward is to click on the contents under the `Browse Content` column.\n",
    "For example, if we click on the `Series`, we can see the following web page:\n",
    "\n",
    "![](./images/Module1/GEO_Website_Screening.png)\n",
    "\n",
    "From the figure, we can see the list data series that are available on GEO, provided with basic information about the series including accession ID, title, type of sequencing platform, organism, number of samples, referenced dataset ID, list of supplementary files, contact person and release data. Of note, the `Supplementary` column also specifies whether there are available raw data in the series. We can apply the filter in these columns to find the datasets that matched our research. Given the data series of interest, we can click on the accession number to further explore the data. \n",
    "\n",
    "Alternatively, if we know the accession number, we can provide it to the search box on the homepage. Now, we will search for the two datasets that we are going to use in the learning module.\n",
    "The GEO website interface with the searching procedure of the example dataset is shown in the figure below:\n",
    "\n",
    "![](./images/Module1/GEO_Website_Searchbox.png)\n",
    "\n",
    "When the searching process is done, a webpage with a detailed record of the example dataset such as published date, title, organism, experiment type, dataset summary, etc. will be shown in the figure below:\n",
    "\n",
    "![](./images/Module1/GEO_Dataset_Page.png)\n",
    "\n",
    "At the bottom of the dataset page, users will find additional information about the dataset such as sequencing platform, number of samples, project ID, and links to download the expression data. Users can also click the `(http)` hyperlink to download all the samples or click `(custom)` to select and download the samples of interest. Note that, expression data downloaded at this step may be raw data and additional data processing needs to be done locally for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0d237-cf6a-465c-93f8-d9bbc6d93a6d",
   "metadata": {},
   "source": [
    "To display the quiz in all the learning sub-modules, it is necessary to have the `IRdisplay` package pre-installed.\n",
    "This package allows quizzes written in `html` format to show up in the notebook. Users can install the `IRdisplay` using the following command:\n",
    "```\n",
    "suppressWarnings(if (!require(\"IRdisplay\")) install.packages(\"IRdisplay\"))\n",
    "suppressWarnings(library(IRdisplay))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d33273-5c2e-42fb-85f7-1b2943631f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command to take the quiz\n",
    "IRdisplay::display_html('<iframe src=\"./Quizzes/Quiz_Submodule1.html\" width=100% height=250></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13964320",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dt-Rquery\"></a>\n",
    "### 1.2. Downloading using R Command Line\n",
    "Users can also using R to query expression data from GEO by using R package specifically built for querying data from the database. In this section, we will download and process the two Alzheimer's datasets from GE), with accession numbers: GSE5281 (Microarray) and GSE153873 (RNA-Seq), using the `GEOQuery` R package. For other databases, we suggest users to look for the designated packages on many R communities such as CRAN or BioConductor.\n",
    "\n",
    "Before starting, users will need to install the `GEOquery` package using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required package\n",
    "suppressMessages({\n",
    "    \n",
    "    if (!require(\"BiocManager\", quietly = TRUE)) {\n",
    "        suppressWarnings(install.packages(\"BiocManager\"))\n",
    "\n",
    "    }  \n",
    "    suppressWarnings(BiocManager::install(\"GEOquery\", update = F))\n",
    "})\n",
    "\n",
    "# Check if the package is installed\n",
    "suppressMessages(library(\"GEOquery\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624fe5a",
   "metadata": {},
   "source": [
    "#### Download Microarray Dataset: GSE5281\n",
    "We can use the `getGEO` function from the `GEOquery` package to download GEO dataset. First, users have to specify the accession ID of the dataset. For this demonstration, we will use the same dataset `GSE5281`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56fd57-3a91-4715-962b-07f43324c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GEO accession ID\n",
    "accession_ID <- \"GSE5281\"\n",
    "\n",
    "\n",
    "# Specify directory to save the data\n",
    "save_Path <- \"./data\"\n",
    "\n",
    "# Create the data folder\n",
    "dir.create(save_Path, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Download the data\n",
    "suppressMessages({\n",
    "    gse <- getGEO(GEO = accession_ID, destdir = save_Path)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983800f-61f1-49e4-9f51-2431875ada39",
   "metadata": {},
   "source": [
    "To use the `getGEO` function, you need to pass the following arguments:\n",
    "\n",
    "- `GEO`: A character string representing the GEO accession ID\n",
    "- `destdir`: A character string representing the destination directory to save the downloaded data.\n",
    "\n",
    "The `getGEO` function will return a list of `ExpressionSet` objects. This list can contain more than 1 object. It is because some datasets on GEO may be derived from different microarray platforms. Therefore, each object in the returned list is with repect to data generated from a particular platform.\n",
    "We can find out how many platforms were used by checking the length of the `gse` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d028647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many platforms used\n",
    "message(paste0(\"Number of platforms: \", length(gse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3cdf0c-578d-4fed-a98a-7c4341af2e7e",
   "metadata": {},
   "source": [
    "The result shows that we have only one dataset that belongs to the microarray platform mentioned GEO dataset page.\n",
    "Next, we can access the gene expression matrix, samples and genes information using the specific accesor functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9ee50-8a54-4a03-956c-72ee4cad4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset from the gse object\n",
    "data <- gse[[1]]\n",
    "\n",
    "# Access to the gene expression matrix\n",
    "GSE5281Exprs <- exprs(data)\n",
    "\n",
    "# Access to the samples information\n",
    "GSE5281Samples <- pData(data)\n",
    "\n",
    "# Check the number of samples and genes\n",
    "print(paste0(\"The dataset contains \", dim(GSE5281Exprs)[2] , \" samples and \", dim(GSE5281Exprs)[1], \" genes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de1fc1",
   "metadata": {},
   "source": [
    "We can check the data tables we have just accessed by specifying the indexes of rows and columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac10fe6-138e-490b-b4a7-e8b292ab93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "message(\"The example of expression matrix\")\n",
    "GSE5281Exprs[1:10, 1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530b7bb-a037-4187-ac2b-e544302714d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "message(\"Example of sample information table\")\n",
    "GSE5281Samples[1:10, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0c982-5c63-483a-9012-9f1c6a15cfae",
   "metadata": {},
   "source": [
    "The ```GSE5281Samples``` contains the metadata of each sample such as title, status, GEO accession, submission data, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff0d9e1-c932-4cd8-bb22-2e9c1421b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command to take the quiz\n",
    "IRdisplay::display_html('<iframe src=\"./Quizzes/Quiz_Submodule1-1.html\" width=100% height=250></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba429e6-ae01-465e-98cd-1f39fa91f621",
   "metadata": {},
   "source": [
    "#### Download RNA-Seq Dataset: GSE153873\n",
    "\n",
    "Microarray data deposited on GEO are usually processed by the authors. In contrast, RNA-Seq data deposited on GEO database are read count matrix without any data normalization. Therefore, there are no `Series Matrix File(s)` available to download. However, the count matrix file is saved as **Supplementary File**. To download it, we will use the function ```getGEOSuppFiles``` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6967ee7-fa40-4f44-8e2d-89275a8ccc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GEO accession ID\n",
    "accession_ID <- \"GSE153873\"\n",
    "\n",
    "# Specify directory to save the data\n",
    "save_Path <- \"./data/GSE153873\"\n",
    "\n",
    "# Download supplentary files\n",
    "tmp <- getGEOSuppFiles(GEO = accession_ID, baseDir = \"./data\", fetch_files = TRUE)\n",
    "\n",
    "# Check files in the directory\n",
    "list.files(save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c780912-0ef6-406b-8653-2fe543e9ffcc",
   "metadata": {},
   "source": [
    "In this code snippet, we use the function getGEOSuppFiles() to download the supplementary files of the dataset GSE153873. The function has the following parameters: \n",
    "- `GEO` – a character parameter that specifies the GEO accession number,\n",
    "- `baseDir` – a character parameter that specifies the directory for downloaded data, and\n",
    "- `fetch_files` – a logical parameter, with TRUE means telling the function to actually download the files and FALSE telling the function to just return the filenames that would have been downloaded.\n",
    "\n",
    "The function returns a data frame in which row names represent the full path to the downloaded files. . We can check the downloaded file in this folder using the function `list.files()`. As we can see in the console output, the raw count data is saved under the name `GSE153873_summary_count.star.txt.gz`. To get the data matrix, users need to run the following command lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f53922-7c04-44c3-a6a1-655ba0851119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the count matrix file:\n",
    "countsFile <- file.path(save_Path, \"GSE153873_summary_count.star.txt.gz\")\n",
    "\n",
    "# Read the count matrix file:\n",
    "GSE153873Exprs <- read.table(countsFile, header = TRUE, sep = \"\\t\", fill = 0, row.names = 1, check.names = FALSE)\n",
    "\n",
    "# Examine the RNASeqExprs:\n",
    "message(\"Examine the read count matrix\")\n",
    "GSE153873Exprs[1:10, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79881b80-f625-4e42-9cbb-9ba6b2d5c788",
   "metadata": {},
   "source": [
    "As we can see, the count matrix file has rows as genes and columns as samples. Similar to the microarray dataset, we use the `getGEO` function to get the sample information as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d4b54-6eb4-4d82-afc0-983869c1e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "suppressMessages({\n",
    "    gse <- getGEO(GEO = accession_ID, destdir = save_Path)\n",
    "})\n",
    "\n",
    "# Extract the dataset from the gse list:\n",
    "data <- gse[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fd5cf-2b94-4966-8e0e-8a56098543dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to the sample information table:\n",
    "GSE153873Samples <- pData(data)\n",
    "\n",
    "# Examine the RNASeqSamples\n",
    "message(\"Examine the sample information\")\n",
    "GSE153873Samples[1:10, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992013a-eeef-47a7-bf24-537f7768f0f2",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dt-manual\"></a>\n",
    "## 2.  Uploading User-Provided Data\n",
    "\n",
    "Users can also directly upload their own data or data downloaded from public databases such as GDC The Cancer Genome Atlas (TCGA), ArrayExpress, etc. to the Cloud environment. However, it is important to note that the submodule is designed to handle gene expression data generated from either microarray or RNA-Seq experiments. For those starting with raw sequencing files (.CEL for microarray or .FASTQ for RNA- Seq), we recommend consulting relevant protocols for alignment and obtaining the expression data table. Accordingly, this section requires the following file types as input:\n",
    "\n",
    "- A gene expression/read count matrix file. The matrix file is a table that contains the gene expression/read counts for each gene in each sample. The matrix can be saved in any format, e.g., TXT, CSV, TSV, etc, depending on what data processing pipelines that users use to generate the matrix file. The rows in the matrix are feature IDs (e.g., probe IDs, Ensemble ID, etc.) while the columns are samples. An example of gene expression matrix is shown as below, in which columns are sample IDs and rows are Ensemble ID:\n",
    "\n",
    "![](./images/Module1/User_Example_Exprs.png)\n",
    "\n",
    "-  A spreadsheet containing sample information, which can be CSV or TSV format. In this spreadsheet, each row represents a sample, and each column represents its attribute, e.g., sample ID, vital status, tissue, platform, etc. An example of this spreadsheet is shown as below, in which users can use `vital_status` as sample conditions for differential analysis:\n",
    "\n",
    "![](./images/Module1/User_Example_Sample.png)\n",
    "\n",
    "\n",
    "### 2.1. Upload to Notebook Instance\n",
    "Users can upload the data directly to the cloud by simply using the user interface of this Jupyter Notebook. The instructions are shown in the following figure:\n",
    "![](./images/Module1/Data_Uploading_VAI.png)\n",
    "\n",
    "### 2.2. Upload to Cloud Storage Bucket\n",
    "Alternately, users can also upload their data to the cloud AWS S3 Bucket. The data may be lost after users delete the notebook instance, so storing them to the S3 bucket allows users to use the data anytime they want. The instructions to upload the data to the Cloud Storage Bucket are shown in the following figure:\n",
    "1. On the webpage of AWS account, search for [S3 service](https://console.aws.amazon.com/s3).\n",
    "2. Select `Create bucket` button to create a new bucket.\n",
    "\n",
    "![](./images/Bucket/bucket1.png)\n",
    "\n",
    "3. Enter the information such as a unique name, region, etc, required for creating the bucket. Note that users can define the access control in this step, and edit the access later once users wants to share their data.\n",
    "\n",
    "![](./images/Bucket/bucket2.png)\n",
    "\n",
    "4. Click `Create bucket` once the all required information are provided.\n",
    "\n",
    "![](./images/Bucket/bucket3.png)\n",
    "\n",
    "5. The dashboard shows all the buckets users created. Click on the bucket's name:\n",
    "\n",
    "![](./images/Bucket/bucket4.png)\n",
    "\n",
    "7. Click on the *Upload*:\n",
    "\n",
    "![](./images/Bucket/bucket5.png)\n",
    "\n",
    "8. Start adding your files to the bucket:\n",
    "\n",
    "![](./images/Bucket/bucket6.png)\n",
    "\n",
    "Once the uploading is done, users can simply load the data to their instance by running the following command syntax in R code block: `system(\"aws s3 cp s3://<BUCKET-NAME>/<FILE-NAME> <DESTINATION>\")`. For example, we run the following command lines to load the dataset GSE5281 we stored in the Cloud Storage Bucket:\n",
    "\n",
    "```\n",
    "# Download the files from S3 Bucket to the \"data\" folder in current directory\n",
    "system(\"aws s3 cp s3://your-unique-name/GSE5281.csv ./data/\")\n",
    "system(\"aws s3 cp s3://your-unique-name/GSE5281_SampleInfo.csv ./data/\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8678d88-94bf-4c37-bc07-769b48cfa2e9",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dt-process\"></a>\n",
    "## 3. Data Processing and Gene Mapping\n",
    "\n",
    "Once the data is downloaded, we need to perform data processing to prepare the data for differential analysis and pathway analysis. The data processing includes the following steps: (i) Data normalization, (ii) Sample condition extraction, and (iii) Gene IDs mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aafb5f",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dp-microarray\"></a>\n",
    "### 3.1. Example of Microarray Dataset: GSE5281\n",
    "\n",
    "#### Data normalization\n",
    "\n",
    "Typically, data normalization can be performed for quality assurance. However, different downstream analysis methods may require different data normalization techniques. Therefore, we suggest users to consult these methods' document to choose the most appropriate normalization technique. For example, if a method requires the expression to be in log-scale normalization, we can check the scale the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc084af7-8440-4ddc-8757-57094b2052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a summary of the expression data using the summary function\n",
    "summary(GSE5281Exprs[, 1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad09d9-8936-4a53-9dde-1b5e04ed845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value range of the expression data using the range function\n",
    "range(GSE5281Exprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a114ba82-ef45-4b29-977c-5c4dc4516aac",
   "metadata": {},
   "source": [
    "From the summary of the data above, we can clearly see that the maximum expression values can be in the scale of thousands, while the average expression values in each sample are below one. One common step is to perform quartile filtering to remove the outlier and missing expression values. Also, we will need to perform a transformation to ensure the distributions of all samples are similar. Then, a `boxplot` can also be generated to see if the data have been correctly normalized. We can use the sample code below to perform all of those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9835afa-ab8e-4557-94b0-5f262694b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the data quantile and remove the NA value\n",
    "qx <- as.numeric(quantile(GSE5281Exprs, c(0., 0.25, 0.5, 0.75, 0.99, 1.0), na.rm = T))\n",
    "# Define LogC variable (boolean) to decide whether or not to perform the log transformation\n",
    "# If 99% of the data > 100 or (range > 50 and 25% of the data > 0), LogC = True and perform log transformation\n",
    "LogC <- (qx[5] > 100) ||\n",
    "    (qx[6]-qx[1] > 50 && qx[2] > 0)\n",
    "# Replace negative values with NA and perform log transformation if logC is True\n",
    "if (LogC) {\n",
    "    GSE5281Exprs[which(GSE5281Exprs <= 0)] <- NaN #\n",
    "    GSE5281Exprs <- log2(GSE5281Exprs+1)\n",
    "}\n",
    "# Plot the boxplot of 10 samples\n",
    "boxplot(x = GSE5281Exprs[, 1:10], outline = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da7e05-3a18-4b11-afd4-20d2bea75aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command to take the quiz\n",
    "IRdisplay::display_html('<iframe src=\"./Quizzes/Quiz_Submodule1-2.html\" width=100% height=250></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74400910",
   "metadata": {},
   "source": [
    "#### Samples Condition Extraction\n",
    "In pathway analysis, it is crucial to determine which conditions of sample are being compared to one another. \n",
    ". In our example, we are comparing gene expression between two patient groups: *normal* - *control* (c) and *Alzheimer’s* - *disease* (d). To this aim, users can execute the following code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column specifying the condition of each sample (normal - c or Alzheimer's - d)\n",
    "GSE5281Samples$condition <- ifelse(grepl(\"normal\", GSE5281Samples$characteristics_ch1.8), \"c\", \"d\")\n",
    "\n",
    "# Factorize the new column\n",
    "GSE5281Samples$condition <- factor(GSE5281Samples$condition)\n",
    "\n",
    "# Add a new column to specify the region of the sample tissue,\n",
    "# use make.names() to remove special characters and\n",
    "# use tolower() to make all characters lowercase\n",
    "GSE5281Samples$region <- make.names(GSE5281Samples$characteristics_ch1.4)\n",
    "GSE5281Samples$region <- tolower(GSE5281Samples$region)\n",
    "\n",
    "# Factorize the newly added column\n",
    "GSE5281Samples$region <- factor(GSE5281Samples$region)\n",
    "\n",
    "# Reorder the samples to match the samples order in the expression data\n",
    "GSE5281Samples <- GSE5281Samples[order(match(rownames(GSE5281Samples), colnames(GSE5281Exprs))), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6dd221-d7ae-400b-8653-6d70d638a669",
   "metadata": {},
   "source": [
    "The samples of the GSE5281 dataset fall into two conditions: *normal* and *Alzheimer’s,* which are specified in the `characteristics_ch1.8` column. Each sample is also associated with a specific brain region, such as the entorhinal cortex, hippocampus, primary visual cortex, and so on, denoted in the `characteristics_ch1.4` column. Consequently, both attributes serve as conditions to determine the groups of patients.\n",
    "\n",
    "The initial step in the code snippet involves the addition of two new columns that represent the sample’s condition and the associated brain region to the sample information. These new columns are essentially cleaner versions of the original `characteristics_ch1.8` and `characteristics_ch1.4` columns. The original columns are often manually curated and may contain special characters or duplicated data, which could potentially lead to errors in the analysis. Hence, it is crucial to perform data cleaning before proceeding with any further steps. We can check the statisitcs of the two new columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the newly added columns\n",
    "summary(GSE5281Samples[, c(\"condition\", \"region\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29013050-344d-47b5-bc48-19bfe1b07a30",
   "metadata": {},
   "source": [
    "#### Gene Mapping\n",
    "\n",
    "In this section, we will create a gene IDs conversion data frame that will be used to convert the gene IDs used in the dataset into the common IDs such as Symbol or Entrez ID. It will be useful in the gene set or pathway analysis, which requires that gene sets and expression data use the same type of gene IDs (e.g., usually Entrez Gene ID or Gene symbol). Dependent on the platform used to generate the expression data, there exists an R package that can be used to annotate the genes in the data to Entrez Gene ID or Gene symbol. For example, the platform of the dataset GSE5281 is GPL570, which has an annotation package on Bioconductor named *hgu133plus2.db*. The list of available annotation packages can be found at: <a href=\"https://bioconductor.org/packages/3.18/data/annotation/\"> https://bioconductor.org/packages/3.18/data/annotation/</a>.\n",
    "\n",
    "To create the gene IDs mapping data frame, users can execute the following code snippets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7f9f8-1b4d-4e9d-b227-a7e51fd76260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the genome wide annotation database for human\n",
    "\n",
    "suppressMessages({\n",
    "    suppressWarnings({\n",
    "        if (!require(\"BiocManager\", quietly = TRUE))\n",
    "            install.packages(\"BiocManager\")\n",
    "            BiocManager::install(\"hgu133plus2.db\", update = F)\n",
    "    })\n",
    "})\n",
    "# Load the hgu133plus2.db\n",
    "library(hgu133plus2.db)\n",
    "\n",
    "# Mappping for GSE5281\n",
    "GSE5281Genes <- rownames(GSE5281Exprs) \n",
    "GSE5281GenesMapping <- AnnotationDbi::select(x = hgu133plus2.db, \n",
    "                                        keys = GSE5281Genes, \n",
    "                                        columns = c(\"PROBEID\", \"SYMBOL\")) \n",
    "colnames(GSE5281GenesMapping) <- c(\"FROM\", \"SYMBOL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f488d-3418-44a9-bb77-8ef8539526fa",
   "metadata": {},
   "source": [
    "To perform the gene IDs mapping, we utilize the `select()` function from the AnnotationDbi package to query various genome-wide annotation databases and to convert gene IDs to the desired IDs. This function requires the following parameters: `x` – an *AnnotationDb* object such as *hgu133plus2.db*, `keys` – a vector containing the current IDs, and `columns` – a vector specifying which types of data (i.e., ID types) can be returned as output. In our example, we choose to return: PROBE ID, SYMBOL, and ENTREZ ID. We then rename the columns of the returned data frame as \"FROM\" and \"SYMBOL\", respectively. Users can examine this dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cabbbb-3e47-478a-89f2-e91f5402941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the mapping dataframe for GSE5281\n",
    "head(GSE5281GenesMapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9723a6-7668-4a2f-8296-236eb0ff45cf",
   "metadata": {},
   "source": [
    "To map the PROBEID to gene SYMBOL, we can use the `map_identifiers` function below as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99555f4-e66b-428e-9b87-1b929b9a0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' @description This function maps identifiers in a dataframe using a mapping dataframe.\n",
    "#'\n",
    "#' @param data_df The dataframe containing the data to be mapped.\n",
    "#' @param mapping_df The dataframe containing the mapping information.\n",
    "#' @param data_source_col The column name in data_df containing the identifiers to be mapped (default: \"PROBEID\").\n",
    "#' @param data_target_col The column name to use for the mapped results in the output dataframe. If NULL, it uses the same name as data_source_col.\n",
    "#' @param data_result_col The optional column name to use for the mapped results in the output dataframe. If provided, it will replace data_target_col.\n",
    "#' @return A dataframe with mapped identifiers.\n",
    "#'\n",
    "# Function to map identifiers, such as probe IDs, to gene symbols using a mapping dataframe.\n",
    "map_identifiers <- function(data_df, mapping_df, data_source_col = \"PROBEID\", data_target_col = \"SYMBOL\", data_result_col = NULL) {\n",
    "\n",
    "    # Merge data_df with mapping_df based on data_source_col\n",
    "    data_df = merge(mapping_df, data_df, by = data_source_col)\n",
    "    # Remove rows with NA values in the data_target_col\n",
    "    data_df <- data_df[!is.na(data_df[, data_target_col]), ]\n",
    "    # Remove duplicated gene symbols, keeping the first occurrence\n",
    "    data_df <- data_df[!duplicated(data_df[[data_target_col]], fromLast = FALSE), ]\n",
    "    # Set row names to the values in data_target_col\n",
    "    rownames(data_df) <- data_df[[data_target_col]]\n",
    "    \n",
    "    # Drop columns from mapping_df that are merged into the result dataframe\n",
    "    if (!is.null(data_result_col)) {\n",
    "        data_df[[data_result_col]] <- data_df[[data_target_col]]\n",
    "        \n",
    "        # Check if data_result_col is the same as data_target_col\n",
    "        if (data_result_col == data_target_col) {\n",
    "            data_df <- data_df[, !(names(data_df) %in% colnames(mapping_df)[1:2])]\n",
    "        } else {\n",
    "            data_df <- data_df[, !(names(data_df) %in% colnames(mapping_df))]\n",
    "        }  \n",
    "    }\n",
    "    \n",
    "    return(data_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9d737-d60c-4306-b6b7-3c5abdeb96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original probe id \n",
    "head(GSE5281Exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014ad0a-d27e-41e4-b013-db5f6cef7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the gene expression to data.frame\n",
    "GSE5281Exprs <- as.data.frame(GSE5281Exprs)\n",
    "# Create a column to contain the gene id (name should match the column in the mapping table)\n",
    "GSE5281Exprs$FROM <- rownames(GSE5281Exprs)\n",
    "# Use the map_identifiers to map the current gene id to the target gene id\n",
    "GSE5281Exprs <- map_identifiers(data_df = GSE5281Exprs, mapping_df = GSE5281GenesMapping, \n",
    "                         data_source_col = \"FROM\", data_target_col = \"SYMBOL\", data_result_col = \"SYMBOL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab40c37-7b41-4443-9b80-4152ea35d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the gene expression data after mapping\n",
    "head(GSE5281Exprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681a2c7-c3ed-48ec-939f-16d576f76295",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dp-rnaseq\"></a>\n",
    "### 3.2. Example of RNA-Seq dataset: GSE153873\n",
    "\n",
    "**Notes:** Most of the packages for analyzing RNA-Seq data embed a normalization process in their functions. Therefore, we will not perform data normalization for the GSE153873 dataset we have just downloaded.\n",
    "\n",
    "#### Sample condition extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b40843-7011-43a5-9d5b-90281f66e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column specifying the condition of the sample,\n",
    "# which can be either normal - c or alzheimer - d\n",
    "RNASeqSampleConditions <- ifelse(grepl(\"Alzheimer\", GSE153873Samples$characteristics_ch1.1), \"d\", \"c\")\n",
    "\n",
    "# Factorize the newly added column\n",
    "GSE153873Samples$condition <- factor(RNASeqSampleConditions)\n",
    "\n",
    "# Reorder the samples to match the samples order in the expression data\n",
    "GSE153873Samples <- GSE153873Samples[order(match(GSE153873Samples$title, colnames(GSE153873Exprs))), ]\n",
    "\n",
    "# Examine the newly added column\n",
    "summary(GSE153873Samples[, c(\"condition\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932e3f9-791a-4b86-ad1c-8e8edcba8195",
   "metadata": {},
   "source": [
    "For this dataset, the `characteristics_ch1.1` column defines the two conditions of the samples: normal and Alzheimer’s. Therefore, we added the `condition` into the `GSE153873Samples` to represent the groups of patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbecef-c1cf-4bd3-8f5f-247b13e80bab",
   "metadata": {},
   "source": [
    "#### RNA-Seq Dataset: GSE153873\n",
    "\n",
    "To create the gene IDs mapping for this dataset, we can run the following command lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a84d9-f1c0-4ae4-98c4-b5d0edd86a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the genome wide annotation database for human\n",
    "suppressMessages({\n",
    "    suppressWarnings({\n",
    "        if (!require(\"BiocManager\", quietly = TRUE))\n",
    "            install.packages(\"BiocManager\")\n",
    "        BiocManager::install(\"org.Hs.eg.db\")\n",
    "    })\n",
    "})\n",
    "# Import the annotation database\n",
    "library(org.Hs.eg.db)\n",
    "\n",
    "# Get current gene IDs used in RNA-Seq dataset\n",
    "GSE153873Genes <- rownames(GSE153873Exprs)\n",
    "\n",
    "# Create a mapping dataframe\n",
    "GSE153873GenesMapping <- AnnotationDbi::select(\n",
    "    x = org.Hs.eg.db, \n",
    "    keys = GSE153873Genes, \n",
    "    keytype = \"SYMBOL\", \n",
    "    columns = c(\"SYMBOL\"))\n",
    "\n",
    "GSE153873GenesMapping <- data.frame(\n",
    "    FROM = GSE153873GenesMapping[,\"SYMBOL\"],\n",
    "    SYMBOL = GSE153873GenesMapping[,\"SYMBOL\"])\n",
    "\n",
    "GSE153873GenesMapping[1:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6666-152f-4468-b60c-c4827fcecf36",
   "metadata": {},
   "source": [
    "For this dataset, gene symbols are used as the IDs. To create the mapping dataframe, we need to load the package `org.Hs.eg.db` package for human’s genome-wide annotation. Users can install this package from Bioconductor following the provided instructions in our code snippet. After installation, it is necessary to load this database and input it as a parameter for the `select(`) function, whose parameters are set to be: `x` – an AnnotationDb `org.Hs.eg.db`, `keys` – a vector containing the current IDs `GSE153873Genes`, `keytype` – a character parameter indicating the type of current gene IDs `SYMBOL`, and `columns` – a vector specifying which types of data are returned as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d21b08-f3f3-4b02-83f9-2c118536261a",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dt-cloud\"></a>\n",
    "## 4. Storing Data to Amazon S3 Storage\n",
    "To run `aws s3` command, the user can either create a code cell within the Jupyter notebook by clicking the + button at the top or \n",
    "click on File -> New -> Terminal to open the terminal \n",
    " \n",
    " \n",
    "To create buckets in R, it is best to use the system command that allows you to run bash commands in R. One thing to note is that S3 bucket names must be globally unique. Please check out the rules [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c970a8-885c-43a0-94ae-1e86c34cc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our bucket name, remember it needs to be unique\n",
    "# Replace <BUCKET_NAME> with the name of your bucket\n",
    "system(\"aws s3 mb s3://your-unique-name\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade9695",
   "metadata": {},
   "source": [
    "The command to copy data from the local disk to the S3 bucket is as follows:\n",
    "\n",
    "`aws s3 cp PATH_TO_LOCAL_FOLDER s3://PATH_IN_S3_BUCKET`\n",
    "\n",
    "For example, if we want to copy the file `./data/GSE5281.rds` we can use the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665869cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting expression data, sample groups, and gene IDs mapping into a list\n",
    "GSE5281Dataset <- list(expression_data = GSE5281Exprs, \n",
    "                       samples = GSE5281Samples, \n",
    "                       genes = GSE5281GenesMapping)\n",
    "\n",
    "GSE153873Dataset <- list(expression_data = GSE153873Exprs, \n",
    "                       samples = GSE153873Samples, \n",
    "                       genes = GSE153873GenesMapping)\n",
    "\n",
    "# Save the data to the local disk using rds format\n",
    "saveRDS(GSE5281Dataset, file = \"./data/GSE5281.rds\")\n",
    "saveRDS(GSE153873Dataset, file = \"./data/GSE153873.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eccf36-1d99-4cc6-914b-511f3306606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <BUCKET_NAME> with name of your bucket that was perviously made\n",
    "system(\"aws s3 cp ./data/GSE5281.rds s3://your-unique-name\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda8b49-b1ac-4d3a-8922-b7d12859e04a",
   "metadata": {},
   "source": [
    "We can download files from AWS S3 Bucket using the following command. Here we are downloading the data to current directory of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e6e0d-943d-4c79-86d5-f0ad25cfca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"aws s3 s3://your-unique-name/GSE5281.rds ./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fc324-a8d7-460b-824e-99a59dfed3da",
   "metadata": {},
   "source": [
    "Now we can try to load the data file that we have just downloaded from S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583748a-b808-4009-9819-b3107306cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data downloaded from S3 bucket in current directory\n",
    "data <- readRDS(\"./GSE5281.rds\")\n",
    "# Print out the keys of the data list\n",
    "names(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88509c9c-2fbf-4e9b-9ed1-22ec5a0d5af4",
   "metadata": {},
   "source": [
    " We will also save the data for the `GSE153873` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e7b9d-5784-46cd-b0e4-5672cf623c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <BUCKET_NAME> with name of your bucket that was perviously made\n",
    "system(\"aws s3 cp ./data/GSE153873.rds s3://your-unique-name\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebce4ce-5731-45cb-85d7-9141a37623a4",
   "metadata": {},
   "source": [
    "<!-- headings -->\n",
    "<a id=\"dt-export\"></a>\n",
    "## 5. Exporting Data\n",
    "\n",
    "When we have successfully processed expression data, we can export the expression data to a `.csv` file format for inspection in other software such as Excel using the `write_csv` function from readr package. In the code below, we will save the raw expression matrix, normalized expression matrix, and grouping information to `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac959e-68f2-43aa-aac0-6e2e9eebd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw and normalized expression matrix to data frames and save them to csv files\n",
    "expression_data <- as.data.frame(GSE5281Exprs)\n",
    "\n",
    "# Create a sub-directory data folder to save the expression matrix if it is not available\n",
    "dir <- getwd()\n",
    "subDir <- \"/data/export/\"\n",
    "path <- paste0(dir, subDir)\n",
    "# check if the saving folder exists\n",
    "if (!file.exists(path)){\n",
    "    dir.create(file.path(path))\n",
    "}\n",
    "# Save expression values and group to the csv files format in the local folder\n",
    "write.csv(expression_data, file = \"./data/export/GSE5281.csv\")\n",
    "write.csv(GSE5281Samples, file = \"./data/samples_GSE5281.csv\")\n",
    "write.csv(GSE5281GenesMapping, file = \"./data/genes_GSE5281.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9d195-4631-4f7f-9a65-ff2cd559c7e7",
   "metadata": {},
   "source": [
    "The `.csv` format is a very simple format that might not suitable to store big datasets. We can export the expression data to `.rds` format, which is more memory efficient for loading and saving the data. We can save all the relevant data in a list and write to the disk using the built in `saveRDS` function, as shown in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939eea2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided a comprehensive guide to accessing, processing, and managing gene expression data for downstream analysis.  We explored methods for downloading data from the NCBI GEO database using both the web interface and the `GEOquery` R package.  We demonstrated data uploading procedures, both directly to the Vertex AI instance and to a persistent Cloud Storage bucket for later retrieval.  Crucially, the notebook detailed data processing steps, including normalization, sample condition extraction, and gene ID mapping, using examples for both microarray (GSE5281) and RNA-Seq (GSE153873) datasets.  Finally, we covered exporting processed data in both CSV and RDS formats, ensuring compatibility with various analysis tools and efficient data storage. These steps provide a robust foundation for subsequent analyses, such as differential expression and pathway enrichment analysis, which will be explored in further modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4cd642",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Remember to move to the next notebook or shut down your instance if you are finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80d26f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86438d1-f5fa-4213-83c4-a5e402715c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
